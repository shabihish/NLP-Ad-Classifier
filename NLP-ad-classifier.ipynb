{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fd22def-dc58-460e-910d-d37e01ed8a4e",
   "metadata": {},
   "source": [
    "# Advertisement Classification Using Naive Bayes \n",
    "In this notebook, we develop, train, and test a Naive Bayes model (also with Additive Smoothing applied) for classification of Divar ads based on the title and descriptions provided.\n",
    "\n",
    "In this project, we're interested in classifying ads only based on their provided title and descriptions and based on a Naive Bayes classification algorithm. Our approach will be to first pre-process the data, then formally define and solve the problem, then also include Additive Smoothing, and finally asses the results. The approach is clearly described at each of the following steps, and also the probelms are answerd."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bdcee1-6ab9-4e81-a17c-7ce3ff473747",
   "metadata": {},
   "source": [
    "## 1 - Packages\n",
    "First, we import all the python packages that we'll need during this assignment.\n",
    "\n",
    "- [numpy](https://www.numpy.org/) is the fundamental package for scientific computing with Python\n",
    "- [pandas](https://pandas.pydata.org/) is a fast, powerful, flexible and easy to use open source data analysis and manipulation tool\n",
    "- [matplotlib](https://matplotlib.org/) is a comprehensive library for creating static, animated, and interactive visualizations in Python\n",
    "- [hazm](https://github.com/sobhe/hazm) is a NLP preprocessing library for Persian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00fb5d30-528f-4996-a341-f99c225e549e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import hazm\n",
    "\n",
    "# Setting matplotlib plotting options\n",
    "plt.rcParams['axes.titlesize'] = 12\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5336055e-dc18-482c-b849-c4d052c569d2",
   "metadata": {},
   "source": [
    "## 2 - Dataset\n",
    "We load the data from the train and test datasets into the corresponding pandas DataFrames using `pd.read_csv(...)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a635bcf-fdb9-4ad9-91d6-99a97547f793",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('Data/divar_train.csv', encoding='utf-8')\n",
    "data_test = pd.read_csv('Data/divar_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d023a83-6148-418f-96e3-60c2f7e69b24",
   "metadata": {},
   "source": [
    "The two dataframes contain 3 columns each, giving each example (row) three different features, which include the title, the  description, and the describing categries.The head of these two loaded datasets is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04bd885c-a0e1-4653-b598-a18dd882fe13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>بلبل خرمایی</td>\n",
       "      <td>سه عدد بلبل خرمایی سه ماهه.از وقتی جوجه بودن خ...</td>\n",
       "      <td>leisure-hobbies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>عینک اسکی در حد</td>\n",
       "      <td>عینک اسکی دبل لنز مارک يو وكس  در حد نو اصلی م...</td>\n",
       "      <td>leisure-hobbies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>تکیه سر تویوتا پرادو</td>\n",
       "      <td>پارچه ای سالم و تمیز.</td>\n",
       "      <td>vehicles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>مجسمه کریستال24%</td>\n",
       "      <td>مجسمه دکوری کریستال بالرین Rcr24%</td>\n",
       "      <td>for-the-home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>کیف و ساک</td>\n",
       "      <td>هر 2 کاملا تمیز هستند</td>\n",
       "      <td>personal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  title                                        description  \\\n",
       "0           بلبل خرمایی  سه عدد بلبل خرمایی سه ماهه.از وقتی جوجه بودن خ...   \n",
       "1       عینک اسکی در حد  عینک اسکی دبل لنز مارک يو وكس  در حد نو اصلی م...   \n",
       "2  تکیه سر تویوتا پرادو                              پارچه ای سالم و تمیز.   \n",
       "3      مجسمه کریستال24%                  مجسمه دکوری کریستال بالرین Rcr24%   \n",
       "4             کیف و ساک                              هر 2 کاملا تمیز هستند   \n",
       "\n",
       "        categories  \n",
       "0  leisure-hobbies  \n",
       "1  leisure-hobbies  \n",
       "2         vehicles  \n",
       "3     for-the-home  \n",
       "4         personal  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "816b9baf-2f72-4947-88ae-dc7157981c8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>کیف مجلسی نو</td>\n",
       "      <td>کیف مجلسی نوی نو</td>\n",
       "      <td>personal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>دیوار کوب نمدی تزیینی</td>\n",
       "      <td>مناسب برای جهاز عروس</td>\n",
       "      <td>for-the-home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>دو تیکه بسیار بسیار تمیز و سالم</td>\n",
       "      <td>با کشوی مخفی و شیک</td>\n",
       "      <td>for-the-home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>مودم</td>\n",
       "      <td>سلام مودم سالم با وسایلش،دیگه ب کارم نمیاد \\nم...</td>\n",
       "      <td>electronic-devices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>تعداد18عددبوقلمون به قیمت عمده</td>\n",
       "      <td>سلام تعدای بوقلمون دارم به علت جابه جایی به فر...</td>\n",
       "      <td>leisure-hobbies</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             title  \\\n",
       "0                     کیف مجلسی نو   \n",
       "1            دیوار کوب نمدی تزیینی   \n",
       "2  دو تیکه بسیار بسیار تمیز و سالم   \n",
       "3                             مودم   \n",
       "4   تعداد18عددبوقلمون به قیمت عمده   \n",
       "\n",
       "                                         description          categories  \n",
       "0                                   کیف مجلسی نوی نو            personal  \n",
       "1                               مناسب برای جهاز عروس        for-the-home  \n",
       "2                                 با کشوی مخفی و شیک        for-the-home  \n",
       "3  سلام مودم سالم با وسایلش،دیگه ب کارم نمیاد \\nم...  electronic-devices  \n",
       "4  سلام تعدای بوقلمون دارم به علت جابه جایی به فر...     leisure-hobbies  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2003c8b-585e-4a81-8320-d6133cc0a12a",
   "metadata": {},
   "source": [
    "## 3 - Pre-Processing\n",
    "Here we will first append the strings of the `title` and `description` columns, then normalize them by applying removing stop words, end of line characters, and lastly by stemming the words i neach of the sentences. We also try lemmatization on the strings, but not precede with it.\n",
    "\n",
    "In the following block, we're appending the title and description columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9faae1e-52b3-49e0-aa40-2f1210fcd2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['text'] = data_train['title'] + ' ' +  data_train['description']\n",
    "data_test['text'] = data_test['title'] + ' ' +data_test['description']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6763ccce-ef05-4edb-b027-a6122738f6d8",
   "metadata": {},
   "source": [
    "### 3.1 - Basic Normalization\n",
    "We import the list of stop words to be removed out of each string. We also define the `remove_stop_words(...)` lambda function, which would remove every occurance of stop words in the given text.\n",
    "**Note**: By stop words, we mean all actual \"stop words,\" all end of line characters, and all punctuation marks as included in the `persian_stop_words.txt` file hereafter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff886f4e-0dde-4699-866d-1cf0aa631e85",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head of the stop_words_and_puctuations list:\n",
      "['!', '\"', '#', '(', ')', '*', ',', '-', '.', '/', ':', '[', ']', '«', '\\\\n', '\\\\r', '»', '،', '؛', '؟', 'آباد', 'آخ', 'آخر', 'آخرها', 'آخه'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('persian_stop_words.txt') as f:\n",
    "    stop_words_and_puctuations = f.read()\n",
    "    stop_words_and_puctuations = stop_words_and_puctuations.split('\\n')\n",
    "\n",
    "print('Head of the stop_words_and_puctuations list:')        \n",
    "print(stop_words_and_puctuations[:25], '\\n')\n",
    "\n",
    "remove_stop_words = lambda lst, stop_words_and_puctuations: list(filter(lambda a: a not in stop_words_and_puctuations, lst))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb05cc8-97db-4de8-b49f-922ad021997a",
   "metadata": {},
   "source": [
    "We do apply the defined function, `remove_stop_words`, to the tokenization output of each of the strings in the `text` columns of both the train and test dataframes. \n",
    "\n",
    "**Note**: The `hazm.word_tokenize(...)` function, splits the text into the building words, also considering some basic grammatical rules of the language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f545e46d-70d5-43f9-8366-40d522aa2238",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['text_normalized'] = data_train['text'].apply(hazm.word_tokenize).apply(remove_stop_words, stop_words_and_puctuations=stop_words_and_puctuations)\n",
    "data_test['text_normalized'] = data_test['text'].apply(hazm.word_tokenize).apply(remove_stop_words, stop_words_and_puctuations=stop_words_and_puctuations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9ff90e-f229-482d-9afa-403e6e595108",
   "metadata": {},
   "source": [
    "Having run the above cell, the `text_normalized` columns of each dataframe should now be a list of all non-stop-word characters. This is shown in the following two cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10fa604a-6820-4269-84f7-9bb1869936f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>categories</th>\n",
       "      <th>text</th>\n",
       "      <th>text_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>بلبل خرمایی</td>\n",
       "      <td>سه عدد بلبل خرمایی سه ماهه.از وقتی جوجه بودن خ...</td>\n",
       "      <td>leisure-hobbies</td>\n",
       "      <td>بلبل خرمایی سه عدد بلبل خرمایی سه ماهه.از وقتی...</td>\n",
       "      <td>[بلبل, خرمایی, سه, عدد, بلبل, خرمایی, سه, ماهه...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>عینک اسکی در حد</td>\n",
       "      <td>عینک اسکی دبل لنز مارک يو وكس  در حد نو اصلی م...</td>\n",
       "      <td>leisure-hobbies</td>\n",
       "      <td>عینک اسکی در حد عینک اسکی دبل لنز مارک يو وكس ...</td>\n",
       "      <td>[عینک, اسکی, حد, عینک, اسکی, دبل, لنز, مارک, ي...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>تکیه سر تویوتا پرادو</td>\n",
       "      <td>پارچه ای سالم و تمیز.</td>\n",
       "      <td>vehicles</td>\n",
       "      <td>تکیه سر تویوتا پرادو پارچه ای سالم و تمیز.</td>\n",
       "      <td>[تکیه, تویوتا, پرادو, پارچه, سالم, تمیز]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>مجسمه کریستال24%</td>\n",
       "      <td>مجسمه دکوری کریستال بالرین Rcr24%</td>\n",
       "      <td>for-the-home</td>\n",
       "      <td>مجسمه کریستال24% مجسمه دکوری کریستال بالرین Rc...</td>\n",
       "      <td>[مجسمه, کریستال, 24, %, مجسمه, دکوری, کریستال,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>کیف و ساک</td>\n",
       "      <td>هر 2 کاملا تمیز هستند</td>\n",
       "      <td>personal</td>\n",
       "      <td>کیف و ساک هر 2 کاملا تمیز هستند</td>\n",
       "      <td>[کیف, ساک, 2, تمیز]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10195</th>\n",
       "      <td>ان هاش 85</td>\n",
       "      <td>نیمه دوم همه چی به شرط در حد خشک 260تا کار</td>\n",
       "      <td>vehicles</td>\n",
       "      <td>ان هاش 85 نیمه دوم همه چی به شرط در حد خشک 260...</td>\n",
       "      <td>[هاش, 85, نیمه, شرط, حد, خشک, 260, کار]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10196</th>\n",
       "      <td>405 دوگانه کارخانه. تمیز</td>\n",
       "      <td>فابریک 4 حلقه لاستیک 205 نو بیمه یکسال تخفیف ب...</td>\n",
       "      <td>vehicles</td>\n",
       "      <td>405 دوگانه کارخانه. تمیز فابریک 4 حلقه لاستیک ...</td>\n",
       "      <td>[405, دوگانه, کارخانه, تمیز, فابریک, 4, حلقه, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10197</th>\n",
       "      <td>بخاری گازی دودکش دار پلار</td>\n",
       "      <td>بخاری نو و بسیار تمیز هستش\\nبا مشتری واقعی کنا...</td>\n",
       "      <td>for-the-home</td>\n",
       "      <td>بخاری گازی دودکش دار پلار بخاری نو و بسیار تمی...</td>\n",
       "      <td>[بخاری, گازی, دودکش, پلار, بخاری, نو, تمیز, مش...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10198</th>\n",
       "      <td>نر کله برنجی چتری</td>\n",
       "      <td>سلام به دلیل کمبود جا واسباب کشی به کمترین قیم...</td>\n",
       "      <td>leisure-hobbies</td>\n",
       "      <td>نر کله برنجی چتری سلام به دلیل کمبود جا واسباب...</td>\n",
       "      <td>[نر, کله, برنجی, چتری, سلام, دلیل, کمبود, واسب...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10199</th>\n",
       "      <td>پراید111سفید</td>\n",
       "      <td>پراید111se\\nسفید.مدل93.درب جلو سمت شاگرد استوک...</td>\n",
       "      <td>vehicles</td>\n",
       "      <td>پراید111سفید پراید111se\\nسفید.مدل93.درب جلو سم...</td>\n",
       "      <td>[پراید, 111, سفید, پراید, 111, se, سفید, مدل, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10200 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           title  \\\n",
       "0                    بلبل خرمایی   \n",
       "1                عینک اسکی در حد   \n",
       "2           تکیه سر تویوتا پرادو   \n",
       "3               مجسمه کریستال24%   \n",
       "4                      کیف و ساک   \n",
       "...                          ...   \n",
       "10195                  ان هاش 85   \n",
       "10196   405 دوگانه کارخانه. تمیز   \n",
       "10197  بخاری گازی دودکش دار پلار   \n",
       "10198          نر کله برنجی چتری   \n",
       "10199               پراید111سفید   \n",
       "\n",
       "                                             description       categories  \\\n",
       "0      سه عدد بلبل خرمایی سه ماهه.از وقتی جوجه بودن خ...  leisure-hobbies   \n",
       "1      عینک اسکی دبل لنز مارک يو وكس  در حد نو اصلی م...  leisure-hobbies   \n",
       "2                                  پارچه ای سالم و تمیز.         vehicles   \n",
       "3                      مجسمه دکوری کریستال بالرین Rcr24%     for-the-home   \n",
       "4                                  هر 2 کاملا تمیز هستند         personal   \n",
       "...                                                  ...              ...   \n",
       "10195         نیمه دوم همه چی به شرط در حد خشک 260تا کار         vehicles   \n",
       "10196  فابریک 4 حلقه لاستیک 205 نو بیمه یکسال تخفیف ب...         vehicles   \n",
       "10197  بخاری نو و بسیار تمیز هستش\\nبا مشتری واقعی کنا...     for-the-home   \n",
       "10198  سلام به دلیل کمبود جا واسباب کشی به کمترین قیم...  leisure-hobbies   \n",
       "10199  پراید111se\\nسفید.مدل93.درب جلو سمت شاگرد استوک...         vehicles   \n",
       "\n",
       "                                                    text  \\\n",
       "0      بلبل خرمایی سه عدد بلبل خرمایی سه ماهه.از وقتی...   \n",
       "1      عینک اسکی در حد عینک اسکی دبل لنز مارک يو وكس ...   \n",
       "2             تکیه سر تویوتا پرادو پارچه ای سالم و تمیز.   \n",
       "3      مجسمه کریستال24% مجسمه دکوری کریستال بالرین Rc...   \n",
       "4                        کیف و ساک هر 2 کاملا تمیز هستند   \n",
       "...                                                  ...   \n",
       "10195  ان هاش 85 نیمه دوم همه چی به شرط در حد خشک 260...   \n",
       "10196  405 دوگانه کارخانه. تمیز فابریک 4 حلقه لاستیک ...   \n",
       "10197  بخاری گازی دودکش دار پلار بخاری نو و بسیار تمی...   \n",
       "10198  نر کله برنجی چتری سلام به دلیل کمبود جا واسباب...   \n",
       "10199  پراید111سفید پراید111se\\nسفید.مدل93.درب جلو سم...   \n",
       "\n",
       "                                         text_normalized  \n",
       "0      [بلبل, خرمایی, سه, عدد, بلبل, خرمایی, سه, ماهه...  \n",
       "1      [عینک, اسکی, حد, عینک, اسکی, دبل, لنز, مارک, ي...  \n",
       "2               [تکیه, تویوتا, پرادو, پارچه, سالم, تمیز]  \n",
       "3      [مجسمه, کریستال, 24, %, مجسمه, دکوری, کریستال,...  \n",
       "4                                    [کیف, ساک, 2, تمیز]  \n",
       "...                                                  ...  \n",
       "10195            [هاش, 85, نیمه, شرط, حد, خشک, 260, کار]  \n",
       "10196  [405, دوگانه, کارخانه, تمیز, فابریک, 4, حلقه, ...  \n",
       "10197  [بخاری, گازی, دودکش, پلار, بخاری, نو, تمیز, مش...  \n",
       "10198  [نر, کله, برنجی, چتری, سلام, دلیل, کمبود, واسب...  \n",
       "10199  [پراید, 111, سفید, پراید, 111, se, سفید, مدل, ...  \n",
       "\n",
       "[10200 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b329311d-999b-4721-a8bb-b1e67b9d62a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>categories</th>\n",
       "      <th>text</th>\n",
       "      <th>text_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>کیف مجلسی نو</td>\n",
       "      <td>کیف مجلسی نوی نو</td>\n",
       "      <td>personal</td>\n",
       "      <td>کیف مجلسی نو کیف مجلسی نوی نو</td>\n",
       "      <td>[کیف, مجلسی, نو, کیف, مجلسی, نوی, نو]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>دیوار کوب نمدی تزیینی</td>\n",
       "      <td>مناسب برای جهاز عروس</td>\n",
       "      <td>for-the-home</td>\n",
       "      <td>دیوار کوب نمدی تزیینی مناسب برای جهاز عروس</td>\n",
       "      <td>[دیوار, کوب, نمدی, تزیینی, مناسب, جهاز, عروس]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>دو تیکه بسیار بسیار تمیز و سالم</td>\n",
       "      <td>با کشوی مخفی و شیک</td>\n",
       "      <td>for-the-home</td>\n",
       "      <td>دو تیکه بسیار بسیار تمیز و سالم با کشوی مخفی و...</td>\n",
       "      <td>[تیکه, تمیز, سالم, کشوی, مخفی]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>مودم</td>\n",
       "      <td>سلام مودم سالم با وسایلش،دیگه ب کارم نمیاد \\nم...</td>\n",
       "      <td>electronic-devices</td>\n",
       "      <td>مودم سلام مودم سالم با وسایلش،دیگه ب کارم نمیا...</td>\n",
       "      <td>[مودم, سلام, مودم, سالم, وسایلش, ب, کارم, نمیا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>تعداد18عددبوقلمون به قیمت عمده</td>\n",
       "      <td>سلام تعدای بوقلمون دارم به علت جابه جایی به فر...</td>\n",
       "      <td>leisure-hobbies</td>\n",
       "      <td>تعداد18عددبوقلمون به قیمت عمده سلام تعدای بوقل...</td>\n",
       "      <td>[تعداد, 18, عددبوقلمون, قیمت, سلام, تعدای, بوق...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>باسکول 300کیلویی</td>\n",
       "      <td>سالمه سالمه بشرط\\nقیمت نوش داخل بازار600تومنه</td>\n",
       "      <td>businesses</td>\n",
       "      <td>باسکول 300کیلویی سالمه سالمه بشرط\\nقیمت نوش دا...</td>\n",
       "      <td>[باسکول, 300, کیلویی, سالمه, سالمه, بشرط, قیمت...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>میز مدیریتی با کنفرانس</td>\n",
       "      <td>میز مدیریتی با کنفرانس \\nتمیز سالم بدون خط و خش</td>\n",
       "      <td>businesses</td>\n",
       "      <td>میز مدیریتی با کنفرانس میز مدیریتی با کنفرانس ...</td>\n",
       "      <td>[میز, مدیریتی, کنفرانس, میز, مدیریتی, کنفرانس,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>باند aiwa</td>\n",
       "      <td>سالم،با اسپیکر</td>\n",
       "      <td>electronic-devices</td>\n",
       "      <td>باند aiwa سالم،با اسپیکر</td>\n",
       "      <td>[باند, aiwa, سالم, اسپیکر]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798</th>\n",
       "      <td>عروس هلندی مولد</td>\n",
       "      <td>پنج تا عروس هلندی،  دو جفت ویک تک،یه جفتش دم ت...</td>\n",
       "      <td>leisure-hobbies</td>\n",
       "      <td>عروس هلندی مولد پنج تا عروس هلندی،  دو جفت ویک...</td>\n",
       "      <td>[عروس, هلندی, مولد, عروس, هلندی, جفت, ویک, تک,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799</th>\n",
       "      <td>ست دستباف دخترانه یکساله نو</td>\n",
       "      <td>ست دخترانه تا یکسال و نیم هم میشه ،کاردست و نو...</td>\n",
       "      <td>personal</td>\n",
       "      <td>ست دستباف دخترانه یکساله نو ست دخترانه تا یکسا...</td>\n",
       "      <td>[ست, دستباف, دخترانه, یکساله, نو, ست, دخترانه,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1800 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                title  \\\n",
       "0                        کیف مجلسی نو   \n",
       "1               دیوار کوب نمدی تزیینی   \n",
       "2     دو تیکه بسیار بسیار تمیز و سالم   \n",
       "3                                مودم   \n",
       "4      تعداد18عددبوقلمون به قیمت عمده   \n",
       "...                               ...   \n",
       "1795                 باسکول 300کیلویی   \n",
       "1796           میز مدیریتی با کنفرانس   \n",
       "1797                        باند aiwa   \n",
       "1798                  عروس هلندی مولد   \n",
       "1799      ست دستباف دخترانه یکساله نو   \n",
       "\n",
       "                                            description          categories  \\\n",
       "0                                      کیف مجلسی نوی نو            personal   \n",
       "1                                  مناسب برای جهاز عروس        for-the-home   \n",
       "2                                    با کشوی مخفی و شیک        for-the-home   \n",
       "3     سلام مودم سالم با وسایلش،دیگه ب کارم نمیاد \\nم...  electronic-devices   \n",
       "4     سلام تعدای بوقلمون دارم به علت جابه جایی به فر...     leisure-hobbies   \n",
       "...                                                 ...                 ...   \n",
       "1795      سالمه سالمه بشرط\\nقیمت نوش داخل بازار600تومنه          businesses   \n",
       "1796    میز مدیریتی با کنفرانس \\nتمیز سالم بدون خط و خش          businesses   \n",
       "1797                                     سالم،با اسپیکر  electronic-devices   \n",
       "1798  پنج تا عروس هلندی،  دو جفت ویک تک،یه جفتش دم ت...     leisure-hobbies   \n",
       "1799  ست دخترانه تا یکسال و نیم هم میشه ،کاردست و نو...            personal   \n",
       "\n",
       "                                                   text  \\\n",
       "0                         کیف مجلسی نو کیف مجلسی نوی نو   \n",
       "1            دیوار کوب نمدی تزیینی مناسب برای جهاز عروس   \n",
       "2     دو تیکه بسیار بسیار تمیز و سالم با کشوی مخفی و...   \n",
       "3     مودم سلام مودم سالم با وسایلش،دیگه ب کارم نمیا...   \n",
       "4     تعداد18عددبوقلمون به قیمت عمده سلام تعدای بوقل...   \n",
       "...                                                 ...   \n",
       "1795  باسکول 300کیلویی سالمه سالمه بشرط\\nقیمت نوش دا...   \n",
       "1796  میز مدیریتی با کنفرانس میز مدیریتی با کنفرانس ...   \n",
       "1797                           باند aiwa سالم،با اسپیکر   \n",
       "1798  عروس هلندی مولد پنج تا عروس هلندی،  دو جفت ویک...   \n",
       "1799  ست دستباف دخترانه یکساله نو ست دخترانه تا یکسا...   \n",
       "\n",
       "                                        text_normalized  \n",
       "0                 [کیف, مجلسی, نو, کیف, مجلسی, نوی, نو]  \n",
       "1         [دیوار, کوب, نمدی, تزیینی, مناسب, جهاز, عروس]  \n",
       "2                        [تیکه, تمیز, سالم, کشوی, مخفی]  \n",
       "3     [مودم, سلام, مودم, سالم, وسایلش, ب, کارم, نمیا...  \n",
       "4     [تعداد, 18, عددبوقلمون, قیمت, سلام, تعدای, بوق...  \n",
       "...                                                 ...  \n",
       "1795  [باسکول, 300, کیلویی, سالمه, سالمه, بشرط, قیمت...  \n",
       "1796  [میز, مدیریتی, کنفرانس, میز, مدیریتی, کنفرانس,...  \n",
       "1797                         [باند, aiwa, سالم, اسپیکر]  \n",
       "1798  [عروس, هلندی, مولد, عروس, هلندی, جفت, ویک, تک,...  \n",
       "1799  [ست, دستباف, دخترانه, یکساله, نو, ست, دخترانه,...  \n",
       "\n",
       "[1800 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d858cbf-850e-43fc-ae94-0e9e082850f3",
   "metadata": {},
   "source": [
    "### 3.2 Stemming and Lemmatization\n",
    "In this section, we do apply stemming and lemmatization to the `text_normalized` columns of the dataframes to lower the variance of the distibutions of words in out dataframes. Please note that although we try out lemmatization, we don't use it further in our actual NLP model, as it comes with a great computional cost over stemming but adds no real extra-value to our model, as we don't care if the generated lammas are a member of the language or not.\n",
    "\n",
    "#### 3.2.1 - Stemming\n",
    "stemming is the process of reducting inflection words into their corresponding roots to lower the distribution of words in the output sentence/dataset. Here we use the `hazm.Stemmer` class for stemming.\n",
    "\n",
    "We first define a stemmer function to be applied to each of the rows our `text_normalized` columns, then apply it both dataframes and store the results in the corresponding `text_normalized_stemmed` columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8244fc22-7496-4de0-94b3-69b7aaa5b641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>categories</th>\n",
       "      <th>text</th>\n",
       "      <th>text_normalized</th>\n",
       "      <th>text_normalized_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>بلبل خرمایی</td>\n",
       "      <td>سه عدد بلبل خرمایی سه ماهه.از وقتی جوجه بودن خ...</td>\n",
       "      <td>leisure-hobbies</td>\n",
       "      <td>بلبل خرمایی سه عدد بلبل خرمایی سه ماهه.از وقتی...</td>\n",
       "      <td>[بلبل, خرمایی, سه, عدد, بلبل, خرمایی, سه, ماهه...</td>\n",
       "      <td>[بلبل, خرما, سه, عدد, بلبل, خرما, سه, ماهه, جو...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>عینک اسکی در حد</td>\n",
       "      <td>عینک اسکی دبل لنز مارک يو وكس  در حد نو اصلی م...</td>\n",
       "      <td>leisure-hobbies</td>\n",
       "      <td>عینک اسکی در حد عینک اسکی دبل لنز مارک يو وكس ...</td>\n",
       "      <td>[عینک, اسکی, حد, عینک, اسکی, دبل, لنز, مارک, ي...</td>\n",
       "      <td>[عینک, اسک, حد, عینک, اسک, دبل, لنز, مارک, يو,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>تکیه سر تویوتا پرادو</td>\n",
       "      <td>پارچه ای سالم و تمیز.</td>\n",
       "      <td>vehicles</td>\n",
       "      <td>تکیه سر تویوتا پرادو پارچه ای سالم و تمیز.</td>\n",
       "      <td>[تکیه, تویوتا, پرادو, پارچه, سالم, تمیز]</td>\n",
       "      <td>[تکیه, تویوتا, پرادو, پارچه, سال, تمیز]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>مجسمه کریستال24%</td>\n",
       "      <td>مجسمه دکوری کریستال بالرین Rcr24%</td>\n",
       "      <td>for-the-home</td>\n",
       "      <td>مجسمه کریستال24% مجسمه دکوری کریستال بالرین Rc...</td>\n",
       "      <td>[مجسمه, کریستال, 24, %, مجسمه, دکوری, کریستال,...</td>\n",
       "      <td>[مجسمه, کریستال, 24, %, مجسمه, دکور, کریستال, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>کیف و ساک</td>\n",
       "      <td>هر 2 کاملا تمیز هستند</td>\n",
       "      <td>personal</td>\n",
       "      <td>کیف و ساک هر 2 کاملا تمیز هستند</td>\n",
       "      <td>[کیف, ساک, 2, تمیز]</td>\n",
       "      <td>[کیف, ساک, 2, تمیز]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10195</th>\n",
       "      <td>ان هاش 85</td>\n",
       "      <td>نیمه دوم همه چی به شرط در حد خشک 260تا کار</td>\n",
       "      <td>vehicles</td>\n",
       "      <td>ان هاش 85 نیمه دوم همه چی به شرط در حد خشک 260...</td>\n",
       "      <td>[هاش, 85, نیمه, شرط, حد, خشک, 260, کار]</td>\n",
       "      <td>[, 85, نیمه, شرط, حد, خشک, 260, کار]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10196</th>\n",
       "      <td>405 دوگانه کارخانه. تمیز</td>\n",
       "      <td>فابریک 4 حلقه لاستیک 205 نو بیمه یکسال تخفیف ب...</td>\n",
       "      <td>vehicles</td>\n",
       "      <td>405 دوگانه کارخانه. تمیز فابریک 4 حلقه لاستیک ...</td>\n",
       "      <td>[405, دوگانه, کارخانه, تمیز, فابریک, 4, حلقه, ...</td>\n",
       "      <td>[405, دوگانه, کارخانه, تمیز, فابریک, 4, حلقه, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10197</th>\n",
       "      <td>بخاری گازی دودکش دار پلار</td>\n",
       "      <td>بخاری نو و بسیار تمیز هستش\\nبا مشتری واقعی کنا...</td>\n",
       "      <td>for-the-home</td>\n",
       "      <td>بخاری گازی دودکش دار پلار بخاری نو و بسیار تمی...</td>\n",
       "      <td>[بخاری, گازی, دودکش, پلار, بخاری, نو, تمیز, مش...</td>\n",
       "      <td>[بخار, گاز, دودک, پلار, بخار, نو, تمیز, مشتر, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10198</th>\n",
       "      <td>نر کله برنجی چتری</td>\n",
       "      <td>سلام به دلیل کمبود جا واسباب کشی به کمترین قیم...</td>\n",
       "      <td>leisure-hobbies</td>\n",
       "      <td>نر کله برنجی چتری سلام به دلیل کمبود جا واسباب...</td>\n",
       "      <td>[نر, کله, برنجی, چتری, سلام, دلیل, کمبود, واسب...</td>\n",
       "      <td>[نر, کله, برنج, چتر, سلا, دلیل, کمبود, واسباب,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10199</th>\n",
       "      <td>پراید111سفید</td>\n",
       "      <td>پراید111se\\nسفید.مدل93.درب جلو سمت شاگرد استوک...</td>\n",
       "      <td>vehicles</td>\n",
       "      <td>پراید111سفید پراید111se\\nسفید.مدل93.درب جلو سم...</td>\n",
       "      <td>[پراید, 111, سفید, پراید, 111, se, سفید, مدل, ...</td>\n",
       "      <td>[پراید, 111, سفید, پراید, 111, se, سفید, مدل, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10200 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           title  \\\n",
       "0                    بلبل خرمایی   \n",
       "1                عینک اسکی در حد   \n",
       "2           تکیه سر تویوتا پرادو   \n",
       "3               مجسمه کریستال24%   \n",
       "4                      کیف و ساک   \n",
       "...                          ...   \n",
       "10195                  ان هاش 85   \n",
       "10196   405 دوگانه کارخانه. تمیز   \n",
       "10197  بخاری گازی دودکش دار پلار   \n",
       "10198          نر کله برنجی چتری   \n",
       "10199               پراید111سفید   \n",
       "\n",
       "                                             description       categories  \\\n",
       "0      سه عدد بلبل خرمایی سه ماهه.از وقتی جوجه بودن خ...  leisure-hobbies   \n",
       "1      عینک اسکی دبل لنز مارک يو وكس  در حد نو اصلی م...  leisure-hobbies   \n",
       "2                                  پارچه ای سالم و تمیز.         vehicles   \n",
       "3                      مجسمه دکوری کریستال بالرین Rcr24%     for-the-home   \n",
       "4                                  هر 2 کاملا تمیز هستند         personal   \n",
       "...                                                  ...              ...   \n",
       "10195         نیمه دوم همه چی به شرط در حد خشک 260تا کار         vehicles   \n",
       "10196  فابریک 4 حلقه لاستیک 205 نو بیمه یکسال تخفیف ب...         vehicles   \n",
       "10197  بخاری نو و بسیار تمیز هستش\\nبا مشتری واقعی کنا...     for-the-home   \n",
       "10198  سلام به دلیل کمبود جا واسباب کشی به کمترین قیم...  leisure-hobbies   \n",
       "10199  پراید111se\\nسفید.مدل93.درب جلو سمت شاگرد استوک...         vehicles   \n",
       "\n",
       "                                                    text  \\\n",
       "0      بلبل خرمایی سه عدد بلبل خرمایی سه ماهه.از وقتی...   \n",
       "1      عینک اسکی در حد عینک اسکی دبل لنز مارک يو وكس ...   \n",
       "2             تکیه سر تویوتا پرادو پارچه ای سالم و تمیز.   \n",
       "3      مجسمه کریستال24% مجسمه دکوری کریستال بالرین Rc...   \n",
       "4                        کیف و ساک هر 2 کاملا تمیز هستند   \n",
       "...                                                  ...   \n",
       "10195  ان هاش 85 نیمه دوم همه چی به شرط در حد خشک 260...   \n",
       "10196  405 دوگانه کارخانه. تمیز فابریک 4 حلقه لاستیک ...   \n",
       "10197  بخاری گازی دودکش دار پلار بخاری نو و بسیار تمی...   \n",
       "10198  نر کله برنجی چتری سلام به دلیل کمبود جا واسباب...   \n",
       "10199  پراید111سفید پراید111se\\nسفید.مدل93.درب جلو سم...   \n",
       "\n",
       "                                         text_normalized  \\\n",
       "0      [بلبل, خرمایی, سه, عدد, بلبل, خرمایی, سه, ماهه...   \n",
       "1      [عینک, اسکی, حد, عینک, اسکی, دبل, لنز, مارک, ي...   \n",
       "2               [تکیه, تویوتا, پرادو, پارچه, سالم, تمیز]   \n",
       "3      [مجسمه, کریستال, 24, %, مجسمه, دکوری, کریستال,...   \n",
       "4                                    [کیف, ساک, 2, تمیز]   \n",
       "...                                                  ...   \n",
       "10195            [هاش, 85, نیمه, شرط, حد, خشک, 260, کار]   \n",
       "10196  [405, دوگانه, کارخانه, تمیز, فابریک, 4, حلقه, ...   \n",
       "10197  [بخاری, گازی, دودکش, پلار, بخاری, نو, تمیز, مش...   \n",
       "10198  [نر, کله, برنجی, چتری, سلام, دلیل, کمبود, واسب...   \n",
       "10199  [پراید, 111, سفید, پراید, 111, se, سفید, مدل, ...   \n",
       "\n",
       "                                 text_normalized_stemmed  \n",
       "0      [بلبل, خرما, سه, عدد, بلبل, خرما, سه, ماهه, جو...  \n",
       "1      [عینک, اسک, حد, عینک, اسک, دبل, لنز, مارک, يو,...  \n",
       "2                [تکیه, تویوتا, پرادو, پارچه, سال, تمیز]  \n",
       "3      [مجسمه, کریستال, 24, %, مجسمه, دکور, کریستال, ...  \n",
       "4                                    [کیف, ساک, 2, تمیز]  \n",
       "...                                                  ...  \n",
       "10195               [, 85, نیمه, شرط, حد, خشک, 260, کار]  \n",
       "10196  [405, دوگانه, کارخانه, تمیز, فابریک, 4, حلقه, ...  \n",
       "10197  [بخار, گاز, دودک, پلار, بخار, نو, تمیز, مشتر, ...  \n",
       "10198  [نر, کله, برنج, چتر, سلا, دلیل, کمبود, واسباب,...  \n",
       "10199  [پراید, 111, سفید, پراید, 111, se, سفید, مدل, ...  \n",
       "\n",
       "[10200 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = hazm.Stemmer()\n",
    "stem_tokenized_sentence = lambda sentence, stemmer: [stemmer.stem(word) for word in sentence]\n",
    "\n",
    "data_train['text_normalized_stemmed'] = data_train['text_normalized'].apply(stem_tokenized_sentence, stemmer=stemmer)\n",
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1344b0a4-4e39-416e-956d-3746d237690d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>categories</th>\n",
       "      <th>text</th>\n",
       "      <th>text_normalized</th>\n",
       "      <th>text_normalized_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>کیف مجلسی نو</td>\n",
       "      <td>کیف مجلسی نوی نو</td>\n",
       "      <td>personal</td>\n",
       "      <td>کیف مجلسی نو کیف مجلسی نوی نو</td>\n",
       "      <td>[کیف, مجلسی, نو, کیف, مجلسی, نوی, نو]</td>\n",
       "      <td>[کیف, مجلس, نو, کیف, مجلس, نو, نو]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>دیوار کوب نمدی تزیینی</td>\n",
       "      <td>مناسب برای جهاز عروس</td>\n",
       "      <td>for-the-home</td>\n",
       "      <td>دیوار کوب نمدی تزیینی مناسب برای جهاز عروس</td>\n",
       "      <td>[دیوار, کوب, نمدی, تزیینی, مناسب, جهاز, عروس]</td>\n",
       "      <td>[دیوار, کوب, نمد, تزیین, مناسب, جهاز, عروس]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>دو تیکه بسیار بسیار تمیز و سالم</td>\n",
       "      <td>با کشوی مخفی و شیک</td>\n",
       "      <td>for-the-home</td>\n",
       "      <td>دو تیکه بسیار بسیار تمیز و سالم با کشوی مخفی و...</td>\n",
       "      <td>[تیکه, تمیز, سالم, کشوی, مخفی]</td>\n",
       "      <td>[تیکه, تمیز, سال, کشو, مخف]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>مودم</td>\n",
       "      <td>سلام مودم سالم با وسایلش،دیگه ب کارم نمیاد \\nم...</td>\n",
       "      <td>electronic-devices</td>\n",
       "      <td>مودم سلام مودم سالم با وسایلش،دیگه ب کارم نمیا...</td>\n",
       "      <td>[مودم, سلام, مودم, سالم, وسایلش, ب, کارم, نمیا...</td>\n",
       "      <td>[مود, سلا, مود, سال, وسایل, ب, کار, نمیاد, مار...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>تعداد18عددبوقلمون به قیمت عمده</td>\n",
       "      <td>سلام تعدای بوقلمون دارم به علت جابه جایی به فر...</td>\n",
       "      <td>leisure-hobbies</td>\n",
       "      <td>تعداد18عددبوقلمون به قیمت عمده سلام تعدای بوقل...</td>\n",
       "      <td>[تعداد, 18, عددبوقلمون, قیمت, سلام, تعدای, بوق...</td>\n",
       "      <td>[تعداد, 18, عددبوقلمون, قیم, سلا, تعدا, بوقلمو...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>باسکول 300کیلویی</td>\n",
       "      <td>سالمه سالمه بشرط\\nقیمت نوش داخل بازار600تومنه</td>\n",
       "      <td>businesses</td>\n",
       "      <td>باسکول 300کیلویی سالمه سالمه بشرط\\nقیمت نوش دا...</td>\n",
       "      <td>[باسکول, 300, کیلویی, سالمه, سالمه, بشرط, قیمت...</td>\n",
       "      <td>[باسکول, 300, کیلو, سالمه, سالمه, بشرط, قیم, ن...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>میز مدیریتی با کنفرانس</td>\n",
       "      <td>میز مدیریتی با کنفرانس \\nتمیز سالم بدون خط و خش</td>\n",
       "      <td>businesses</td>\n",
       "      <td>میز مدیریتی با کنفرانس میز مدیریتی با کنفرانس ...</td>\n",
       "      <td>[میز, مدیریتی, کنفرانس, میز, مدیریتی, کنفرانس,...</td>\n",
       "      <td>[میز, مدیریت, کنفرانس, میز, مدیریت, کنفرانس, ت...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>باند aiwa</td>\n",
       "      <td>سالم،با اسپیکر</td>\n",
       "      <td>electronic-devices</td>\n",
       "      <td>باند aiwa سالم،با اسپیکر</td>\n",
       "      <td>[باند, aiwa, سالم, اسپیکر]</td>\n",
       "      <td>[باند, aiwa, سال, اسپیکر]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798</th>\n",
       "      <td>عروس هلندی مولد</td>\n",
       "      <td>پنج تا عروس هلندی،  دو جفت ویک تک،یه جفتش دم ت...</td>\n",
       "      <td>leisure-hobbies</td>\n",
       "      <td>عروس هلندی مولد پنج تا عروس هلندی،  دو جفت ویک...</td>\n",
       "      <td>[عروس, هلندی, مولد, عروس, هلندی, جفت, ویک, تک,...</td>\n",
       "      <td>[عروس, هلند, مولد, عروس, هلند, جف, ویک, تک, جف...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799</th>\n",
       "      <td>ست دستباف دخترانه یکساله نو</td>\n",
       "      <td>ست دخترانه تا یکسال و نیم هم میشه ،کاردست و نو...</td>\n",
       "      <td>personal</td>\n",
       "      <td>ست دستباف دخترانه یکساله نو ست دخترانه تا یکسا...</td>\n",
       "      <td>[ست, دستباف, دخترانه, یکساله, نو, ست, دخترانه,...</td>\n",
       "      <td>[س, دستباف, دخترانه, یکساله, نو, س, دخترانه, ن...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1800 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                title  \\\n",
       "0                        کیف مجلسی نو   \n",
       "1               دیوار کوب نمدی تزیینی   \n",
       "2     دو تیکه بسیار بسیار تمیز و سالم   \n",
       "3                                مودم   \n",
       "4      تعداد18عددبوقلمون به قیمت عمده   \n",
       "...                               ...   \n",
       "1795                 باسکول 300کیلویی   \n",
       "1796           میز مدیریتی با کنفرانس   \n",
       "1797                        باند aiwa   \n",
       "1798                  عروس هلندی مولد   \n",
       "1799      ست دستباف دخترانه یکساله نو   \n",
       "\n",
       "                                            description          categories  \\\n",
       "0                                      کیف مجلسی نوی نو            personal   \n",
       "1                                  مناسب برای جهاز عروس        for-the-home   \n",
       "2                                    با کشوی مخفی و شیک        for-the-home   \n",
       "3     سلام مودم سالم با وسایلش،دیگه ب کارم نمیاد \\nم...  electronic-devices   \n",
       "4     سلام تعدای بوقلمون دارم به علت جابه جایی به فر...     leisure-hobbies   \n",
       "...                                                 ...                 ...   \n",
       "1795      سالمه سالمه بشرط\\nقیمت نوش داخل بازار600تومنه          businesses   \n",
       "1796    میز مدیریتی با کنفرانس \\nتمیز سالم بدون خط و خش          businesses   \n",
       "1797                                     سالم،با اسپیکر  electronic-devices   \n",
       "1798  پنج تا عروس هلندی،  دو جفت ویک تک،یه جفتش دم ت...     leisure-hobbies   \n",
       "1799  ست دخترانه تا یکسال و نیم هم میشه ،کاردست و نو...            personal   \n",
       "\n",
       "                                                   text  \\\n",
       "0                         کیف مجلسی نو کیف مجلسی نوی نو   \n",
       "1            دیوار کوب نمدی تزیینی مناسب برای جهاز عروس   \n",
       "2     دو تیکه بسیار بسیار تمیز و سالم با کشوی مخفی و...   \n",
       "3     مودم سلام مودم سالم با وسایلش،دیگه ب کارم نمیا...   \n",
       "4     تعداد18عددبوقلمون به قیمت عمده سلام تعدای بوقل...   \n",
       "...                                                 ...   \n",
       "1795  باسکول 300کیلویی سالمه سالمه بشرط\\nقیمت نوش دا...   \n",
       "1796  میز مدیریتی با کنفرانس میز مدیریتی با کنفرانس ...   \n",
       "1797                           باند aiwa سالم،با اسپیکر   \n",
       "1798  عروس هلندی مولد پنج تا عروس هلندی،  دو جفت ویک...   \n",
       "1799  ست دستباف دخترانه یکساله نو ست دخترانه تا یکسا...   \n",
       "\n",
       "                                        text_normalized  \\\n",
       "0                 [کیف, مجلسی, نو, کیف, مجلسی, نوی, نو]   \n",
       "1         [دیوار, کوب, نمدی, تزیینی, مناسب, جهاز, عروس]   \n",
       "2                        [تیکه, تمیز, سالم, کشوی, مخفی]   \n",
       "3     [مودم, سلام, مودم, سالم, وسایلش, ب, کارم, نمیا...   \n",
       "4     [تعداد, 18, عددبوقلمون, قیمت, سلام, تعدای, بوق...   \n",
       "...                                                 ...   \n",
       "1795  [باسکول, 300, کیلویی, سالمه, سالمه, بشرط, قیمت...   \n",
       "1796  [میز, مدیریتی, کنفرانس, میز, مدیریتی, کنفرانس,...   \n",
       "1797                         [باند, aiwa, سالم, اسپیکر]   \n",
       "1798  [عروس, هلندی, مولد, عروس, هلندی, جفت, ویک, تک,...   \n",
       "1799  [ست, دستباف, دخترانه, یکساله, نو, ست, دخترانه,...   \n",
       "\n",
       "                                text_normalized_stemmed  \n",
       "0                    [کیف, مجلس, نو, کیف, مجلس, نو, نو]  \n",
       "1           [دیوار, کوب, نمد, تزیین, مناسب, جهاز, عروس]  \n",
       "2                           [تیکه, تمیز, سال, کشو, مخف]  \n",
       "3     [مود, سلا, مود, سال, وسایل, ب, کار, نمیاد, مار...  \n",
       "4     [تعداد, 18, عددبوقلمون, قیم, سلا, تعدا, بوقلمو...  \n",
       "...                                                 ...  \n",
       "1795  [باسکول, 300, کیلو, سالمه, سالمه, بشرط, قیم, ن...  \n",
       "1796  [میز, مدیریت, کنفرانس, میز, مدیریت, کنفرانس, ت...  \n",
       "1797                          [باند, aiwa, سال, اسپیکر]  \n",
       "1798  [عروس, هلند, مولد, عروس, هلند, جف, ویک, تک, جف...  \n",
       "1799  [س, دستباف, دخترانه, یکساله, نو, س, دخترانه, ن...  \n",
       "\n",
       "[1800 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test['text_normalized_stemmed'] = data_test['text_normalized'].apply(stem_tokenized_sentence, stemmer=stemmer)\n",
    "data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f180ce0e-bc2a-4280-be6b-fe5252597293",
   "metadata": {},
   "source": [
    "#### 3.2.2 Lemmatization\n",
    "Lemmatization works just like stemming, with the difference that it always returns lemmas of te given words, i.e. the returned word will be a member of the language because it searcher corpora to find the lemmas. Here we use the `hazm.Lemmatizer` class for lemmatization.\n",
    "\n",
    "Just like for stemming, we define a lemmatizer function to be applied to each tokenized sentence, and apply it to columns `text_normalized` of the dataframes. Note that we don't store the results in our dataframes, because we're not going to use them further on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f447eee-88aa-4b38-9138-da9db16b7678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [بلبل, خرما, سه, عدد, بلبل, خرما, سه, ماهه, جو...\n",
       "1        [عینک, اسکی, حد, عینک, اسکی, دبل, لنز, مارک, ي...\n",
       "2                 [تکیه, تویوتا, پرادو, پارچه, سالم, تمیز]\n",
       "3        [مجسمه, کریستال, 24, %, مجسمه, دکوری, کریستال,...\n",
       "4                                      [کیف, ساک, 2, تمیز]\n",
       "                               ...                        \n",
       "10195              [هاش, 85, نیمه, شرط, حد, خشک, 260, کار]\n",
       "10196    [405, دوگانه, کارخانه, تمیز, فابریک, 4, حلقه, ...\n",
       "10197    [بخاری, گازی, دودکش, پلار, بخاری, نو, تمیز, مش...\n",
       "10198    [نر, کله, برنجی, چتر, سلام, دلیل, کمبود, واسبا...\n",
       "10199    [پراید, 111, سفید, پراید, 111, se, سفید, مدل, ...\n",
       "Name: text_normalized, Length: 10200, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = hazm.Lemmatizer()\n",
    "lemmatize_tokenized_sentence = lambda sentence, lemmatizer: [lemmatizer.lemmatize(word) for word in sentence]\n",
    "\n",
    "data_train['text_normalized'].apply(lemmatize_tokenized_sentence, lemmatizer=lemmatizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3bab3390-a432-429b-b15f-2fbb0a2fc96c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      [کیف, مجلس, نو, کیف, مجلس, نو, نو]\n",
       "1             [دیوار, کوب, نمد, تزیین, مناسب, جهاز, عروس]\n",
       "2                           [تیکه, تمیز, سالم, کشو, مخفی]\n",
       "3       [مودم, سلام, مودم, سالم, وسایل, ب, کاشت#کار, ن...\n",
       "4       [تعداد, 18, عددبوقلمون, قیمت, سلام, تعدای, بوق...\n",
       "                              ...                        \n",
       "1795    [باسکول, 300, کیلویی, سالمه, سالمه, بشرط, قیمت...\n",
       "1796    [میز, مدیریت, کنفرانس, میز, مدیریت, کنفرانس, ت...\n",
       "1797                           [باند, aiwa, سالم, اسپیکر]\n",
       "1798    [عروس, هلند, مولد, عروس, هلند, جفت, ویک, تک, ج...\n",
       "1799    [ست, دستباف, دخترانه, یکساله, نو, ست, دخترانه,...\n",
       "Name: text_normalized, Length: 1800, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test['text_normalized'].apply(lemmatize_tokenized_sentence, lemmatizer=lemmatizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19f4fe3-3d27-43d1-aded-10333c9f4aec",
   "metadata": {},
   "source": [
    "## 4 - Naive Bayes\n",
    "Our objective is to classify the rows and put them into one of the 6 given categories based solely on the `text_normalized_stemmed` column of each respective dataframe. We're gonna be using the `data_train` dataframe for training our model, and the `data_test`dataframe to test the prediction accuracy.\n",
    "\n",
    "Note that we'll be using a Naive Bayes model for our prediction. The overall process will be as follows:\n",
    "- We define and parametrized our Naive Bayes model\n",
    "- We train the model based on the probability of each word to be describing of a class\n",
    "- We lastly test the accuracy of the model on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cab2614-53be-41b9-ae01-3a2d48222e81",
   "metadata": {},
   "source": [
    "### 4.1 - Model\n",
    "#### 4.1.1 - Definitions\n",
    "We use the bag of words model to describe the dependencies between our classes and the describing words. According to this model, only existence of words in the descriptions of each of the classes comprises the probablities of each of those words being related to each class.\n",
    "\n",
    "We calculate $P(c|x) = \\frac{P(x|c)P(c)}{P(x)}$, that is, the probility of a single class given an example word. The following are the components of this relation in our problem:\n",
    "- **Posterior Probibility**: The probability of having class `c` given a word `x` in the describing text\n",
    "- **Likelihood:** The probability of having word `x` describe class `c`\n",
    "- **Class Prior Probability** Probability: The total probability of having class `c` for all words in all describing texts\n",
    "- **Predictor Prior Probability(Evidence)** Probability: The total probability of of word `x` being chosen while choosing a random word out of the total distribution of words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc4b165-454d-4063-b227-38c34d47b351",
   "metadata": {},
   "source": [
    "#### 4.1.2 - Bigrams\n",
    "In the two following examples, the word `get` is used in two different meanings:\n",
    "- On the Elearn, if you navigate to the grades section, you can get a summary of all your grades.\n",
    "- Just get up, we're already late.\n",
    "\n",
    "In the first sentence, `get` means to fetch something from somewhere(the website here). In the second one, `get` is part of the `get up` phrasal verb which makes it particularly different from the first example.\n",
    "\n",
    "In our example, using bigrams will definitely help, mainly due to the fact that `get up`, could definitely be then detected as a phrasal verb which changes the derived meaning greatly in our bag of words model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa7cae3-de3b-4319-bfd6-8fca4560a499",
   "metadata": {},
   "source": [
    "#### 4.1.3 - Training\n",
    "In this phase, we train the Naive Bayes model by calculating the probalities $P(C|X)$, $P(X|C)$, $P(C)$. Note that we don't use $P(X)$ in the **test phase**, because probability normalization does not have any effects on the maximum values of probabilites for each of among each of the classes.\n",
    "\n",
    "We first derive a numpy array of all words used in both of the dataframes (using the `text_normalized_stemmed` columns). This is done by applying using the `numpy.union1d` function iteratively to take a union of all words seen anywhere in our data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22f0b88b-622e-44d2-8717-85cf336f9c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', '!!', '!!!', '!!!!', '!!!!!', '!!!!!!!', '!؟', '###برا', '#3',\n",
       "       '#ارسال_رایگ', '#توجه', '#تک', '#فروش_هوو', '#٥', '$', '$NUM',\n",
       "       '$NUM********', '$NUM/$NUM', '$NUM=مهد', '$NUMGSM'], dtype='<U118')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_of_words = np.array([], dtype=str)\n",
    "for row in (data_train.append(data_test))['text_normalized_stemmed'].to_numpy():\n",
    "    set_of_words = np.union1d(set_of_words, row)\n",
    "set_of_words[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f224c8c4-07db-4137-9f0b-e9e02e746bdc",
   "metadata": {},
   "source": [
    "We now iterate over the rows in the training set based on the class name. We count the number of occurances of each of the `set_of_words` words in each of our classes (categories) and store the results in the `word_df` Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67f5b3cd-9797-4fb8-b517-df2180dc014c",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = np.unique(data_train['categories'].to_numpy())\n",
    "\n",
    "words_columns = ['category']\n",
    "words_columns.extend(set_of_words)\n",
    "words_df = pd.DataFrame(columns=words_columns)\n",
    "\n",
    "for category in np.unique(data_train['categories'].to_numpy()):\n",
    "    tmp_df = data_train[data_train['categories']==category]\n",
    "    tmp_dict = dict(zip(set_of_words, [0]*len(set_of_words)))\n",
    "    words = []\n",
    "    for row in tmp_df['text_normalized_stemmed'].to_numpy():\n",
    "        words.extend(row)\n",
    "    for word in set(words):\n",
    "        tmp_dict[word] = words.count(word)\n",
    "    tmp_dict['category'] = category\n",
    "    words_df = words_df.append(tmp_dict, ignore_index=True)\n",
    "words_df = words_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e9eb3c0-5774-426f-aceb-65ea14d47a13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "      <th>!!</th>\n",
       "      <th>!!!</th>\n",
       "      <th>!!!!</th>\n",
       "      <th>!!!!!</th>\n",
       "      <th>!!!!!!!</th>\n",
       "      <th>!؟</th>\n",
       "      <th>###برا</th>\n",
       "      <th>#3</th>\n",
       "      <th>...</th>\n",
       "      <th>ﻳﻜﺠﺎ</th>\n",
       "      <th>ﻳﻪ</th>\n",
       "      <th>ﻻﺳﺘﻴﻚ</th>\n",
       "      <th>：</th>\n",
       "      <th>：$NUM</th>\n",
       "      <th>：۲شب</th>\n",
       "      <th>￼</th>\n",
       "      <th>👠کف</th>\n",
       "      <th>💥بخون</th>\n",
       "      <th>🔴🔴</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>businesses</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>electronic-devices</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>for-the-home</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>leisure-hobbies</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>personal</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vehicles</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 21768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             category      !!  !!!  !!!!  !!!!!  !!!!!!!  !؟  ###برا  #3  ...  \\\n",
       "0          businesses  72   1    1     1      0        0   0       0   0  ...   \n",
       "1  electronic-devices  18   1    1     1      0        1   0       0   0  ...   \n",
       "2        for-the-home  54   1    2     0      0        0   0       1   1  ...   \n",
       "3     leisure-hobbies  37   2    0     0      2        0   1       0   0  ...   \n",
       "4            personal  26   3    4     0      0        0   0       0   0  ...   \n",
       "5            vehicles  13   2    2     2      0        0   0       0   0  ...   \n",
       "\n",
       "   ﻳﻜﺠﺎ  ﻳﻪ  ﻻﺳﺘﻴﻚ  ：  ：$NUM  ：۲شب  ￼  👠کف  💥بخون  🔴🔴  \n",
       "0     0   0      0  1      0     0  1    0      0   0  \n",
       "1     0   0      0  1      0     0  0    0      0   0  \n",
       "2     0   0      0  0      0     0  0    0      0   0  \n",
       "3     1   0      0  1      1     1  0    0      0   0  \n",
       "4     0   0      0  0      0     0  0    0      0   0  \n",
       "5     0   2      0  0      0     0  0    0      0   2  \n",
       "\n",
       "[6 rows x 21768 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12956c83-5b4f-44be-8f7a-2e8e43103412",
   "metadata": {},
   "source": [
    "Now from the derived `words_df` dataframe, we count the number of occurances of each of the words in each of our classes, the number of total occurances per word, and the number of total words in the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ac03b28-63f5-49a0-87dc-c48f01ba31db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_of_total_words: 145978\n"
     ]
    }
   ],
   "source": [
    "number_of_words_per_class = words_df.iloc[:, 1:].sum(axis=1)\n",
    "number_of_occurances_per_word = words_df.iloc[:, 1:].sum(axis=0)\n",
    "number_of_total_words = number_of_occurances_per_word.sum(axis=0)\n",
    "\n",
    "# probabilities_df = words_df.iloc[:, 1:].div(number_of_words_per_class, axis=0)\n",
    "print('number_of_total_words: {}'.format(number_of_total_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9526af41-b7c7-409f-9a89-0fba79d8578d",
   "metadata": {},
   "source": [
    "We then calculate the probabilities of each of the words describing the given classes, of each of the classes, and of each of the classes given each of the words. Note that for the test phase, we'll not be using the probabilities of each of the classes given each of the words.\n",
    "\n",
    "**Note**: As some words are not seen at all in some classes' describing texts, we lastly fill the `nan` values resulted from divisions by zero by 0's.\n",
    "\n",
    "**Note**: The calculations are exactly based on the formulas provided above and in the CA descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e93b0e1e-b20e-46c1-9927-35a39f077efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>!!</th>\n",
       "      <th>!!!</th>\n",
       "      <th>!!!!</th>\n",
       "      <th>!!!!!</th>\n",
       "      <th>!!!!!!!</th>\n",
       "      <th>!؟</th>\n",
       "      <th>###برا</th>\n",
       "      <th>#3</th>\n",
       "      <th>#ارسال_رایگ</th>\n",
       "      <th>...</th>\n",
       "      <th>ﻳﻜﺠﺎ</th>\n",
       "      <th>ﻳﻪ</th>\n",
       "      <th>ﻻﺳﺘﻴﻚ</th>\n",
       "      <th>：</th>\n",
       "      <th>：$NUM</th>\n",
       "      <th>：۲شب</th>\n",
       "      <th>￼</th>\n",
       "      <th>👠کف</th>\n",
       "      <th>💥بخون</th>\n",
       "      <th>🔴🔴</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002966</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000637</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002707</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001486</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001190</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 21767 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   !!       !!!      !!!!    !!!!!   !!!!!!!       !؟  \\\n",
       "0  0.002966  0.000041  0.000041  0.000041  0.00000  0.000000  0.00000   \n",
       "1  0.000637  0.000035  0.000035  0.000035  0.00000  0.000035  0.00000   \n",
       "2  0.002707  0.000050  0.000100  0.000000  0.00000  0.000000  0.00000   \n",
       "3  0.001486  0.000080  0.000000  0.000000  0.00008  0.000000  0.00004   \n",
       "4  0.001190  0.000137  0.000183  0.000000  0.00000  0.000000  0.00000   \n",
       "5  0.000486  0.000075  0.000075  0.000075  0.00000  0.000000  0.00000   \n",
       "\n",
       "    ###برا       #3  #ارسال_رایگ  ...     ﻳﻜﺠﺎ        ﻳﻪ  ﻻﺳﺘﻴﻚ         ：  \\\n",
       "0  0.00000  0.00000      0.00000  ...  0.00000  0.000000    0.0  0.000041   \n",
       "1  0.00000  0.00000      0.00000  ...  0.00000  0.000000    0.0  0.000035   \n",
       "2  0.00005  0.00005      0.00005  ...  0.00000  0.000000    0.0  0.000000   \n",
       "3  0.00000  0.00000      0.00000  ...  0.00004  0.000000    0.0  0.000040   \n",
       "4  0.00000  0.00000      0.00000  ...  0.00000  0.000000    0.0  0.000000   \n",
       "5  0.00000  0.00000      0.00000  ...  0.00000  0.000075    0.0  0.000000   \n",
       "\n",
       "     ：$NUM     ：۲شب         ￼  👠کف  💥بخون        🔴🔴  \n",
       "0  0.00000  0.00000  0.000041  0.0    0.0  0.000000  \n",
       "1  0.00000  0.00000  0.000000  0.0    0.0  0.000000  \n",
       "2  0.00000  0.00000  0.000000  0.0    0.0  0.000000  \n",
       "3  0.00004  0.00004  0.000000  0.0    0.0  0.000000  \n",
       "4  0.00000  0.00000  0.000000  0.0    0.0  0.000000  \n",
       "5  0.00000  0.00000  0.000000  0.0    0.0  0.000075  \n",
       "\n",
       "[6 rows x 21767 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability_of_words_given_clases = words_df.iloc[:, 1:].div(number_of_words_per_class, axis=0)\n",
    "probability_of_classes = number_of_words_per_class/number_of_total_words\n",
    "probability_of_classes_given_words = (probability_of_words_given_clases.mul(probability_of_classes, axis=0))\\\n",
    "                                                                        .div(number_of_occurances_per_word/number_of_total_words, axis=1)\n",
    "probability_of_classes_given_words = probability_of_classes_given_words.fillna(0)\n",
    "\n",
    "probability_of_words_given_clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d711cf1a-4ec2-44a3-8049-4f2a8782fa57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>!!</th>\n",
       "      <th>!!!</th>\n",
       "      <th>!!!!</th>\n",
       "      <th>!!!!!</th>\n",
       "      <th>!!!!!!!</th>\n",
       "      <th>!؟</th>\n",
       "      <th>###برا</th>\n",
       "      <th>#3</th>\n",
       "      <th>#ارسال_رایگ</th>\n",
       "      <th>...</th>\n",
       "      <th>ﻳﻜﺠﺎ</th>\n",
       "      <th>ﻳﻪ</th>\n",
       "      <th>ﻻﺳﺘﻴﻚ</th>\n",
       "      <th>：</th>\n",
       "      <th>：$NUM</th>\n",
       "      <th>：۲شب</th>\n",
       "      <th>￼</th>\n",
       "      <th>👠کف</th>\n",
       "      <th>💥بخون</th>\n",
       "      <th>🔴🔴</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.327273</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.081818</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.245455</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.168182</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.118182</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.059091</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 21767 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              !!  !!!  !!!!  !!!!!  !!!!!!!   !؟  ###برا   #3  #ارسال_رایگ  \\\n",
       "0  0.327273  0.1  0.1  0.25    0.0      0.0  0.0     0.0  0.0          0.0   \n",
       "1  0.081818  0.1  0.1  0.25    0.0      1.0  0.0     0.0  0.0          0.0   \n",
       "2  0.245455  0.1  0.2  0.00    0.0      0.0  0.0     1.0  1.0          1.0   \n",
       "3  0.168182  0.2  0.0  0.00    1.0      0.0  1.0     0.0  0.0          0.0   \n",
       "4  0.118182  0.3  0.4  0.00    0.0      0.0  0.0     0.0  0.0          0.0   \n",
       "5  0.059091  0.2  0.2  0.50    0.0      0.0  0.0     0.0  0.0          0.0   \n",
       "\n",
       "   ...  ﻳﻜﺠﺎ   ﻳﻪ  ﻻﺳﺘﻴﻚ         ：  ：$NUM  ：۲شب    ￼  👠کف  💥بخون   🔴🔴  \n",
       "0  ...   0.0  0.0    0.0  0.333333    0.0   0.0  1.0  0.0    0.0  0.0  \n",
       "1  ...   0.0  0.0    0.0  0.333333    0.0   0.0  0.0  0.0    0.0  0.0  \n",
       "2  ...   0.0  0.0    0.0  0.000000    0.0   0.0  0.0  0.0    0.0  0.0  \n",
       "3  ...   1.0  0.0    0.0  0.333333    1.0   1.0  0.0  0.0    0.0  0.0  \n",
       "4  ...   0.0  0.0    0.0  0.000000    0.0   0.0  0.0  0.0    0.0  0.0  \n",
       "5  ...   0.0  1.0    0.0  0.000000    0.0   0.0  0.0  0.0    0.0  1.0  \n",
       "\n",
       "[6 rows x 21767 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability_of_classes_given_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc150203-ee8d-4f99-99f9-d3f25c2451d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.166299\n",
       "1    0.193694\n",
       "2    0.136644\n",
       "3    0.170519\n",
       "4    0.149653\n",
       "5    0.183192\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability_of_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb252849-d745-4c01-9d48-e9d11bd29a96",
   "metadata": {},
   "source": [
    "#### 4.1.4 - Testing\n",
    "We test our model by calculating the probability of each test set example text belonging to each of our classes. We then without normalizing the output prbabilities, take the class with the maximally computed prbability as the predicted class and report it.\n",
    "\n",
    "For the calculation of the probabilities, we use the following formula:\n",
    "$$P(C|X)=P(C)*P(x_1|C)*P(x_2|C)...*P(x_n|C)$$\n",
    "where C is the vector of our classes,$P(C)$ denotes the vector of probabilities for each of the classes as calculated by the number of total word per class over the number of total words, $P(x_i|C)$ denotes the vector of probabilities of a word `x_i` given each of the classes, and $P(C|X)$ is the probability of each of the classes given a sentence `X`(of belonging to the classes).\n",
    "\n",
    "We fisrt start by implementing the bare Naive Bayes algorithm for testing. This is done in the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "17762ebe-e4f6-437e-9254-5d2316f7dd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(text:list, probability_of_words_given_clases, probability_of_classes, classes):\n",
    "    out = 1\n",
    "    for word in text:\n",
    "        out = probability_of_words_given_clases[word] * out\n",
    "    out *= probability_of_classes\n",
    "    return classes[out.to_numpy().argmax()]\n",
    "\n",
    "predictions = data_test['text_normalized_stemmed'].apply(test, probability_of_words_given_clases=probability_of_words_given_clases,\\\n",
    "                                           probability_of_classes=probability_of_classes,\\\n",
    "                                          classes = words_df['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b047f45-2dc8-41ce-aad5-7ab0e54645c3",
   "metadata": {},
   "source": [
    "We did apply the `test(...)` function to each of the test set examples, to make predictions by taking the maximally probable class as claculated by the above formula as the prediction result for each example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "015d3412-ed43-4fc9-9ea9-0ecc0ab2ffbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 personal\n",
       "1             for-the-home\n",
       "2             for-the-home\n",
       "3               businesses\n",
       "4               businesses\n",
       "               ...        \n",
       "1795            businesses\n",
       "1796            businesses\n",
       "1797    electronic-devices\n",
       "1798       leisure-hobbies\n",
       "1799              personal\n",
       "Name: text_normalized_stemmed, Length: 1800, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5ee0f954-298c-43d9-8144-f88c8edc6514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model: 0.3927777777777778\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model: {}'.format(((data_test['categories']==predictions)*1).sum()/len(data_test['categories'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72abbe82-2119-4aa5-8191-ab0a3ef963fc",
   "metadata": {},
   "source": [
    "The accuracy of the initial Naive Bayes model is too low. This is caused because if a single word's probability given a class is 0, i.e. it is now seen in anywhere describing that class, then multiplying it to other probabilities of the words in the given sentence given that class according to the above equation, makes the total probability of that sentence given that class 0, and this is overly affecting our current model's results. For solving this problem, we use **Additive Smoothing** as an alternative for calculating probabilities of each of the words given each of the classes.\n",
    "\n",
    "We implement Additive Smoothing using the following formula:\n",
    "\n",
    "$$P(x|c) = \\frac{(c_x+1)}{(n_c+|V|+1)}$$\n",
    "where $c_x$ defines the number of occurances of the word `x` in c's description in the train set, $n_c$ denotes the total number of words ever used in class `s`'s text, and $|V|$ is the total number of words in the train set. \n",
    "\n",
    "Intuitively, this is setting the probabilities of each of the words not seen anywhere describing a class not to 0 any more, but to a very small number that is very close to zero but does not make the whole product 0 when multiplied.\n",
    "\n",
    "The implementation is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a09d4101-5ab8-4a59-b675-12a4610a59c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>!!</th>\n",
       "      <th>!!!</th>\n",
       "      <th>!!!!</th>\n",
       "      <th>!!!!!</th>\n",
       "      <th>!!!!!!!</th>\n",
       "      <th>!؟</th>\n",
       "      <th>###برا</th>\n",
       "      <th>#3</th>\n",
       "      <th>#ارسال_رایگ</th>\n",
       "      <th>...</th>\n",
       "      <th>ﻳﻜﺠﺎ</th>\n",
       "      <th>ﻳﻪ</th>\n",
       "      <th>ﻻﺳﺘﻴﻚ</th>\n",
       "      <th>：</th>\n",
       "      <th>：$NUM</th>\n",
       "      <th>：۲شب</th>\n",
       "      <th>￼</th>\n",
       "      <th>👠کف</th>\n",
       "      <th>💥بخون</th>\n",
       "      <th>🔴🔴</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000429</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000331</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000222</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 21767 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   !!       !!!      !!!!     !!!!!   !!!!!!!        !؟  \\\n",
       "0  0.000429  0.000012  0.000012  0.000012  0.000006  0.000006  0.000006   \n",
       "1  0.000109  0.000011  0.000011  0.000011  0.000006  0.000011  0.000006   \n",
       "2  0.000331  0.000012  0.000018  0.000006  0.000006  0.000006  0.000006   \n",
       "3  0.000222  0.000018  0.000006  0.000006  0.000018  0.000006  0.000012   \n",
       "4  0.000161  0.000024  0.000030  0.000006  0.000006  0.000006  0.000006   \n",
       "5  0.000081  0.000017  0.000017  0.000017  0.000006  0.000006  0.000006   \n",
       "\n",
       "     ###برا        #3  #ارسال_رایگ  ...      ﻳﻜﺠﺎ        ﻳﻪ     ﻻﺳﺘﻴﻚ  \\\n",
       "0  0.000006  0.000006     0.000006  ...  0.000006  0.000006  0.000006   \n",
       "1  0.000006  0.000006     0.000006  ...  0.000006  0.000006  0.000006   \n",
       "2  0.000012  0.000012     0.000012  ...  0.000006  0.000006  0.000006   \n",
       "3  0.000006  0.000006     0.000006  ...  0.000012  0.000006  0.000006   \n",
       "4  0.000006  0.000006     0.000006  ...  0.000006  0.000006  0.000006   \n",
       "5  0.000006  0.000006     0.000006  ...  0.000006  0.000017  0.000006   \n",
       "\n",
       "          ：     ：$NUM      ：۲شب         ￼       👠کف     💥بخون        🔴🔴  \n",
       "0  0.000012  0.000006  0.000006  0.000012  0.000006  0.000006  0.000006  \n",
       "1  0.000011  0.000006  0.000006  0.000006  0.000006  0.000006  0.000006  \n",
       "2  0.000006  0.000006  0.000006  0.000006  0.000006  0.000006  0.000006  \n",
       "3  0.000012  0.000012  0.000012  0.000006  0.000006  0.000006  0.000006  \n",
       "4  0.000006  0.000006  0.000006  0.000006  0.000006  0.000006  0.000006  \n",
       "5  0.000006  0.000006  0.000006  0.000006  0.000006  0.000006  0.000017  \n",
       "\n",
       "[6 rows x 21767 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AS_probability_of_words_given_clases = (words_df.iloc[:, 1:] + 1).div(number_of_words_per_class + number_of_total_words + 1, axis=0)\n",
    "AS_probability_of_words_given_clases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b261cb0-a770-4c36-b285-8898239f9718",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "We see that no elements in the above matrix have a value of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "286ef527-6cec-43aa-814f-2f77495a8fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AS_test(text:list, probability_of_words_given_clases, probability_of_classes, classes):\n",
    "    out = 1\n",
    "    for word in text:\n",
    "        out = probability_of_words_given_clases[word] * out\n",
    "    out *= probability_of_classes\n",
    "    return classes[out.to_numpy().argmax()]\n",
    "\n",
    "AS_predictions = data_test['text_normalized_stemmed'].apply(test, probability_of_words_given_clases=AS_probability_of_words_given_clases,\\\n",
    "                                           probability_of_classes=probability_of_classes,\\\n",
    "                                          classes = words_df['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de5d234-2ff6-4839-bc82-8f90b964bd19",
   "metadata": {},
   "source": [
    "We did apply the `AS_test(...)` function to each of the test set examples, to make AS_predictions by taking the maximally probable class as claculated by the above formula as the prediction result for each example. Note that we did pass `AS_probability_of_words_given_clases` as the parameter to the `AS_test(...)` function this time around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "03480e25-a9ad-4e05-98a4-deb9c794f761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 personal\n",
       "1             for-the-home\n",
       "2             for-the-home\n",
       "3       electronic-devices\n",
       "4          leisure-hobbies\n",
       "               ...        \n",
       "1795    electronic-devices\n",
       "1796            businesses\n",
       "1797    electronic-devices\n",
       "1798       leisure-hobbies\n",
       "1799              personal\n",
       "Name: text_normalized_stemmed, Length: 1800, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AS_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "da9d0996-181d-449c-9085-3215e96d155a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additive Smoothing accuracy: 0.8611111111111112\n"
     ]
    }
   ],
   "source": [
    "print('Additive Smoothing accuracy: {}'.format(((data_test['categories']==AS_predictions)*1).sum()/len(data_test['categories'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9caddb-bc12-4b9f-b4fd-d3adca948281",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "The prediction accuracy is much higher using Additive Smoothing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8050cd5-0e21-44d5-a534-207d88f8a279",
   "metadata": {},
   "source": [
    "#### 4.1.5 - Bar Plots\n",
    "We plot the bar chart of the number of occurances of the top 5 words describing each of our classes in the <u>train set</u>. This is done by using the `bar(...)` function of the `matplotlib` library while iterating over all the categories and by giving the top words' names and frequencies to the plotter. The result is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eb8988ef-000f-4e5d-b993-54fe447ff161",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize = (15, 10))\n",
    "for i, category in enumerate(categories):\n",
    "    tmp_df = words_df.iloc[i, 1:].sort_values(ascending=False)\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.bar(tmp_df.keys()[:5],tmp_df[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797f47f1-d5f1-4ea5-9136-974ec25dfd64",
   "metadata": {},
   "source": [
    "#### 4.1.6 - Assesments\n",
    "We define several methods to test the \"wellness\" of our proposed model. These include the following:\n",
    "- Prediction accuracy as computed over the whole dataset\n",
    "- Precisions computed respective to each of the classes\n",
    "- Recalls computed respective to each of the classes\n",
    "- F1-scores computed respective to each of the classes\n",
    "- Macro, Weighted, and Micro F1-scores calculated for the whole dataset\n",
    "\n",
    "The F1-scores are used when False predictions do matter. The resean why we don't use precision or recall on their own, instead of computing their F1-score, is that precision gives importance to the false positive (FP) cases while recall, gives importance to the false negative (FN) predictions. combining them, we make sure that we're taking into account both the cases so that we can have a better estimation of the models total wellness, for not prediction falsely.\n",
    "\n",
    "An example of having a high recall but low precision, is having a model that predicts 1 for every example in the test set in a binary class problem. This way, the recall will be equal to one, as we have FN=0. This model obviously does not provide a good fit and has a very low precision. Now suppose that we have a model that predicts True some True examples and is very picky. It also does not True for any negative examples as well a a bunch of positive examples. This model would then have a high precision and low recall. Therefore, we use the F1-score for assesments, as it takes the **harmonic mean** of both the precision and recall of the model. The advantages of this tipe of mean is as follows:\n",
    "- Is not significantly affected by fluctuations\n",
    "- Does not give weight to large values\n",
    "- Is capable of algebric treatment\n",
    "\n",
    "In the following cell, we iterate over the classes and compute precisions, recalls, and F1-scoresbased on the given formulas (in the CA descriptions) for each of them. We also store the F1-scores calculated in lists for further use.\n",
    "\n",
    "**Note**: The report table was removed, and was replaced by the following results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "677fe5fd-e3d7-41e6-b9a5-df40884ee139",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category: businesses\n",
      "\t precision : 0.212990937                    AS_precision: 0.760252366         \n",
      "\t recall    : 0.940000000                    AS_recall: 0.803333333         \n",
      "\t F1        : 0.347290640                    AS_F1: 0.781199352         \n",
      "\n",
      "\n",
      "accuracy  : 0.392777778                    AS_accuracy: 0.861111111         \n",
      "\n",
      "\n",
      "category: electronic-devices\n",
      "\t precision : 0.861538462                    AS_precision: 0.849849850         \n",
      "\t recall    : 0.186666667                    AS_recall: 0.943333333         \n",
      "\t F1        : 0.306849315                    AS_F1: 0.894154818         \n",
      "\n",
      "\n",
      "accuracy  : 0.392777778                    AS_accuracy: 0.861111111         \n",
      "\n",
      "\n",
      "category: for-the-home\n",
      "\t precision : 0.885245902                    AS_precision: 0.874524715         \n",
      "\t recall    : 0.360000000                    AS_recall: 0.766666667         \n",
      "\t F1        : 0.511848341                    AS_F1: 0.817051510         \n",
      "\n",
      "\n",
      "accuracy  : 0.392777778                    AS_accuracy: 0.861111111         \n",
      "\n",
      "\n",
      "category: leisure-hobbies\n",
      "\t precision : 0.876543210                    AS_precision: 0.895470383         \n",
      "\t recall    : 0.236666667                    AS_recall: 0.856666667         \n",
      "\t F1        : 0.372703412                    AS_F1: 0.875638842         \n",
      "\n",
      "\n",
      "accuracy  : 0.392777778                    AS_accuracy: 0.861111111         \n",
      "\n",
      "\n",
      "category: personal\n",
      "\t precision : 0.886956522                    AS_precision: 0.871287129         \n",
      "\t recall    : 0.340000000                    AS_recall: 0.880000000         \n",
      "\t F1        : 0.491566265                    AS_F1: 0.875621891         \n",
      "\n",
      "\n",
      "accuracy  : 0.392777778                    AS_accuracy: 0.861111111         \n",
      "\n",
      "\n",
      "category: vehicles\n",
      "\t precision : 0.946236559                    AS_precision: 0.925925926         \n",
      "\t recall    : 0.293333333                    AS_recall: 0.916666667         \n",
      "\t F1        : 0.447837150                    AS_F1: 0.921273032         \n",
      "\n",
      "\n",
      "accuracy  : 0.392777778                    AS_accuracy: 0.861111111         \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "F1_scores = []\n",
    "AS_F1_scores = []\n",
    "\n",
    "for category in categories:\n",
    "    class_predictions = predictions[predictions == category]\n",
    "    class_AS_predictions = AS_predictions[AS_predictions == category]\n",
    "    class_data_test = data_test[data_test['categories'] == category]\n",
    "    \n",
    "    class_detection_status = (class_predictions == ((data_test['categories'])[predictions == category]))\n",
    "    AS_class_detection_status = (class_AS_predictions == ((data_test['categories'])[AS_predictions == category]))\n",
    "\n",
    "    correct_detected_class = class_detection_status.sum()\n",
    "    AS_correct_detected_class = AS_class_detection_status.sum()\n",
    "\n",
    "    all_detected_class = len(class_predictions)\n",
    "    AS_all_detected_class = len(class_AS_predictions)\n",
    "\n",
    "    total_class = len(class_data_test)\n",
    "    \n",
    "    precision = correct_detected_class / all_detected_class\n",
    "    AS_precision = AS_correct_detected_class / AS_all_detected_class\n",
    "    \n",
    "    recall = correct_detected_class / total_class\n",
    "    AS_recall = AS_correct_detected_class / total_class\n",
    "    \n",
    "    F1 = 2 * (precision * recall) / (precision + recall)\n",
    "    AS_F1 = 2 * (AS_precision * AS_recall) / (AS_precision + AS_recall)\n",
    "    \n",
    "    F1_scores.append(F1)\n",
    "    AS_F1_scores.append(AS_F1)\n",
    "    \n",
    "    print('category: {}'.format(category))\n",
    "    print('\\t {2:10}: {0:30} AS_precision: {1:20}'.format(str(\"%.9f\" % precision), str(\"%.9f\" % AS_precision), 'precision'))\n",
    "    print('\\t {2:10}: {0:30} AS_recall: {1:20}'.format(str(\"%.9f\" % recall), str(\"%.9f\" % AS_recall), 'recall'))\n",
    "    print('\\t {2:10}: {0:30} AS_F1: {1:20}'.format(str(\"%.9f\" % F1), str(\"%.9f\" % AS_F1), 'F1'))\n",
    "    print('\\n')\n",
    "    \n",
    "    accuracy = (data_test['categories']==predictions).sum()/len(data_test['categories'])\n",
    "    AS_accuracy = (data_test['categories']==AS_predictions).sum()/len(data_test['categories'])\n",
    "    print('{2:10}: {0:30} AS_accuracy: {1:20}'.format(str(\"%.9f\" % accuracy), str(\"%.9f\" % AS_accuracy), 'accuracy'))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607a009a-1d1d-43ae-8146-ea167f5ab20f",
   "metadata": {},
   "source": [
    "Multi class metrics, are estimations of the wellness of a multi-class model results based on the precision, recall, and F1-score values. We also take three types of means out of the F1-scores respective to each of the classes to asses the wellness of the whole model. These are as follows:\n",
    "- **Marco-F1**: Is the average of all F1-scores for all the classes\n",
    "- **Weighted-F1**: Is the weighted average of all F1-scores for all the classes, weighted based on the number of examples per each class in the test set\n",
    "- **Mirco-F1**: Is the same as the precision of the model, as computed by combining the class sets and taking the precision or recall\n",
    "\n",
    "Here we implemented the two first averages in the following cell. Micro-F1 is the same as precision as already mentioned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "25599913-eaba-470d-b525-4feaf6fc24a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t macro_F1  : 0.413015854                    AS_macro_F1: 0.860823241         \n",
      "\t weighted_F1: 0.413015854                    AS_weighted_F1: 0.860823241         \n",
      "\t micro_F1  : 0.392777778                    AS_micro_F1: 0.861111111         \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "macro_F1 = sum(F1_scores)/len(F1_scores)\n",
    "AS_macro_F1 = sum(AS_F1_scores)/len(F1_scores)\n",
    "\n",
    "weighted_F1 = 0\n",
    "AS_weighted_F1 = 0\n",
    "for i, category in enumerate(categories):\n",
    "    weighted_F1 += F1_scores[i] * (data_test['categories'] == category).sum()\n",
    "    AS_weighted_F1 += AS_F1_scores[i] * (data_test['categories'] == category).sum()\n",
    "weighted_F1 /= len(data_test)\n",
    "AS_weighted_F1 /= len(data_test)\n",
    "\n",
    "micro_F1 = (data_test['categories']==predictions).sum()/len(data_test['categories'])\n",
    "AS_micro_F1 = (data_test['categories']==AS_predictions).sum()/len(data_test['categories'])\n",
    "print('\\t {2:10}: {0:30} AS_macro_F1: {1:20}'.format(str(\"%.9f\" % macro_F1), str(\"%.9f\" % AS_macro_F1), 'macro_F1'))\n",
    "print('\\t {2:10}: {0:30} AS_weighted_F1: {1:20}'.format(str(\"%.9f\" % weighted_F1), str(\"%.9f\" % AS_weighted_F1), 'weighted_F1'))\n",
    "print('\\t {2:10}: {0:30} AS_micro_F1: {1:20}'.format(str(\"%.9f\" % micro_F1), str(\"%.9f\" % AS_micro_F1), 'micro_F1'))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb62ba64-59c3-4bad-9d3f-287de6a04d2e",
   "metadata": {},
   "source": [
    "The resulting values, show a that the AS model, has a good generalization to the test data (over 85 percent), but the bare Nauve Bayes model does not. The AS model shows good recall and precision for classes, and the F1 averages are also good. Also, it has accuracy and maxro averages of over 0.85 as needed in this CA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f972111f-c34b-4410-97b7-4e16c5ac6bff",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "We've reached the acceptance cutoff."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de62d0db-8e24-4e78-ba3c-70dfdd45a737",
   "metadata": {},
   "source": [
    "Bellow, 5 examples of our AS model (model with Additive Smoothing) predicting wrong are shown:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "852dc3a8-f8b7-4163-84d3-0ea7405decd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20     True\n",
       "21     True\n",
       "22     True\n",
       "23     True\n",
       "24     True\n",
       "25     True\n",
       "26     True\n",
       "27    False\n",
       "28    False\n",
       "29    False\n",
       "30     True\n",
       "31     True\n",
       "32     True\n",
       "33     True\n",
       "34     True\n",
       "35    False\n",
       "36     True\n",
       "37     True\n",
       "38     True\n",
       "39     True\n",
       "40     True\n",
       "41     True\n",
       "42     True\n",
       "43     True\n",
       "44     True\n",
       "45     True\n",
       "46     True\n",
       "47     True\n",
       "48     True\n",
       "49    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data_test['categories'] == AS_predictions)[20:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7d7376-cf72-4143-808a-cdba9d5cb5b0",
   "metadata": {},
   "source": [
    "The biggest problem in our prediction not being true %100 of the time, is that we used an oversimplified model, i.e. the bag of words model, which did not take into account the relations between words in a sentense. Other causes may include descriptions not being clear, etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
